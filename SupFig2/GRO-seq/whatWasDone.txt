# an example of what was run - some of the file names may not be correct
##### Processing
# convert sra files to fastq
bash ~/Dropbox/Scripts/ProcessingShells/process_SRA_AD.sh ./ ./

# get to the output from above directory
cd FASTQ

# trim the reads
bash /Users/acd13/Dropbox/Scripts/ProcessingShells/trim_galore_SE.sh /Users/acd13/Desktop/GROseq/L3/FASTQ
# STDOUT was copied to text files in the directory

# Map the trimmed reads
bash /Users/acd13/Dropbox/Scripts/GROseq_alignment_bowtie2.sh /Users/acd13/Desktop/GROseq/L3/FASTQ /Users/acd13/Desktop/GROseq/L3/bowtie2Bams

# get strand specific reads, and filter for reads with quality MAPQ (>30 in this case), and remove dups (not sure if I'll use that or not)
bash /Users/acd13/Dropbox/Scripts/GRO_and_RNA_seq_scripts/mapqFilterAndStrandSpecificSplit.sh /Users/acd13/Desktop/GROseq/EE/bowtie2Bams

# After some work I decided that merging the replicates was going to be useful, so I merged the filtered bams
samtools merge EE_RNAi_groseq_filt.merged.bam SRR639127_1_trimmed.fq.raw.srt.filt.srt.bam SRR639128_1_trimmed.fq.raw.srt.filt.srt.bam

# for possible use down stream I created Homer Tag files
makeTagDirectory HomerTags/merged/ -genome ce10 -checkGC L3_groseq_filt.merged.bam

###### Quantification
# This was done for all of the sampels, and replace a simple coverageBed that I had been using
analyzeRepeats.pl /Users/acd13/Desktop/ce10GeneModelsFromGersteinEtAl/<refseq.gtf> ce10 -strand + -rpkm -count genes -d ./../bowtie2Bams/homerTags/SRR639134/ > SRR639134.homerAnalyzeRepeats.txt
